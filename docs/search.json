[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "RECURSOS TÉCNICOS",
    "section": "",
    "text": "MODELOS SEMI ESTRUCTURALES PARA EL CRÉDITO AL CONSUMO\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nApr 14, 2023\n\n\nLuis Ortiz-Cevallos\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nApr 11, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "MODELOS SEMI ESTRUCTURALES PARA EL CRÉDITO AL CONSUMO",
    "section": "",
    "text": "Al observar la evolución del crédito hacia consumo provisto por el sistema bancario guatemalteco y disponible en @SECMCADATOS, se observa una series con una tendendencia estocástica.\n\nlibrary(\"zoo\")\nlibrary(\"xts\")\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(kableExtra)\nlibrary(xtable)\nlibrary(tidyr)\nlibrary(quantmod)\nlibrary(RColorBrewer)\nlibrary(gridExtra)\n#CARGAMOS DATOS MENSUALES\nDATA_MES&lt;-as.xts(read.zoo(\"GT_MES.csv\", index.column = 1,\n          sep = \";\", header=TRUE, format = \"%Y-%m-%d\"))\nCREDITO&lt;-DATA_MES$CRED\nCREDITO&lt;-data.frame(date=index(CREDITO), coredata(CREDITO))\nCREDITO&lt;-filter(CREDITO, date &gt;= \"2008-01-01\")\ncolnames(CREDITO)&lt;-c(\"date\",\"CREDITO\")\nCREDITO&lt;-mutate(CREDITO, CONSUMO=log(CREDITO))\nG&lt;-ggplot(CREDITO, aes(x=date, y=CONSUMO))\nG&lt;-G+labs(y=\"Logaritmo\",\n          x=\"Fecha\", title = \"Guatemala: evolución del crédito al consumo\",\n          caption = \"https://www.secmca.org/wp-content/uploads/2023/03/REPORTE_INDICADO\nRES_BANCARIOS_MARZO_2023.xlsx\")+\n  geom_line(size=1.5)\nG\n\n\n\n\nEl proceso de generación de la serie del crédito al consumo puede explicarse a través de la identificación de diferentes innovaciones. Una de ellas, las llamaré tecnológicas (en general uso ese término para referir los factores que pueden producir una mayor inclusión financiera independientemente si es producto de políticas o nuevas tecnologías), la segunda las de denanda y la tercera de absorción fiscal.\nPara este ejercicio de identificación sigo la metodología propuesta por @BLANCHARD88 y estimo la forma reducida de un Vector Autorregresivo integrado por la tasa de crecimiento de la cartera de consumo nominal (\\(\\Delta c_{t}\\)), la tasa de crecimiento del PIB (\\(\\Delta y_{t}\\)) y el porcentaje de los activos de los sistemas bancarios en títulos y valores públicos (\\(\\Delta y_{t}\\)). La representación de este VAR como un proceso de media móviles está dado por:\n\\[\\begin{equation}\nX_{t}=\\left( \\begin{array}{c}\n\\Delta c_{t} \\\\\n\\Delta y_{t} \\\\\n\\Delta x_{t}\n\\end{array}\n\\right)=A(L)e_{t}\n\\label{e1}\n\\end{equation}\\]\nConsidero \\(A(0)=I\\) y \\(\\Sigma_e=E(e e^{\\tau})\\) como la matriz de varianza y covarianza de la forma reducida del VAR mostrado en \\(\\ref{e1}\\). Y supongo, primero que el crédito hacia consumo, la actividad económica y la exposición del sistema bancario hacia valores del gobierno son producidos a través de tres procesos estructurales independientes con shocks de varianza unitaria. Y segundo, que uno de esos procesos, el de las innovaciones tecnológicas, es el responsable de la tendencia estocástica observada en el crédito para consumo. Con base en lo anterior defino un VAR estructural cuya representación como un proceso de medias móviles es el siguiente:\n\\[\\begin{equation}\nX_{t}=C(L)\\epsilon_{t}=\\left( \\begin{array}{ccc}\nC_{1,1}(L) & C_{1,2}(L) & C_{1,3}(L)\\\\\nC_{2,1}(L) & C_{2,2}(L) & C_{2,3}(L)\\\\\nC_{3,1}(L) & C_{3,2}(L) & C_{3,3}(L)\n\\end{array}\n\\right)\\epsilon_{t}\n\\label{e2}\n\\end{equation}\\]\nSiendo \\(\\Sigma_{\\epsilon}=E(\\epsilon \\epsilon^{\\tau})=I\\) la matriz de varianza y covarianza de los shocks estructurales, los cuales son independientes y con varianza unitaria, y \\(C_{1,2}(1)=C_{1,3}(1)=0\\), indicando que el shock de demanda y fiscal sobre las variables tasa de crecimiento del PIB y porcentaje de activos invertidos en valores soberanos, en su orden, no tienen efectos de largo plazo en el crédito nominal para consumo.\nEl proceso y resultado de la estimación es el siguiente:\n\nCRED       &lt;-DATA_MES$CRED\nFISCAL     &lt;-DATA_MES$PUB\nCRED       &lt;-CRED[\"2008-01-01/2022-09-01\"]\nep1        &lt;-endpoints(CRED , on = \"quarters\")\nCRED       &lt;-period.apply(CRED  , INDEX = ep1, FUN = sum)\nDCRED      &lt;-diff(100*log(CRED ), lag=4)\nFISCAL     &lt;-FISCAL[\"2008-01-01/2022-09-01\"]\nep2        &lt;-endpoints(FISCAL , on = \"quarters\")\nTASA       &lt;-period.apply(FISCAL, INDEX = ep2, FUN = max)\nDATA_TRIM   &lt;-as.xts(read.zoo(\"TRIM_GT.csv\", index.column = 1,\n                      sep = \";\", header=TRUE, format = \"%Y-%m-%d\"))\nPIB         &lt;-DATA_TRIM$PIB\nPIB         &lt;-PIB[\"2001-03-01/2022-09-01\"]\nDPIB        &lt;-diff(100*log(PIB), lag=4)\n#COMBINAR\nBASE       &lt;-merge(DCRED, DPIB,join=\"left\")\nBASE       &lt;-merge(BASE,  FISCAL,join=\"left\")\nBASE       &lt;-data.frame(date=index(BASE), coredata(BASE))\ncolnames(BASE)&lt;-c(\"date\",\"c\", \"y\", 'x')\nDATA       &lt;-dplyr::select(BASE, date, c,y,x)\ncolnames(DATA)&lt;-c(\"date\", \"c\", \"y\", 'x')\nDATA       &lt;-filter(DATA, date &gt;= \"2016-03-01\")\nDATA       &lt;-xts(DATA[,-1], order.by=as.Date(DATA[,1], \"%Y/%m/%d\"))\nlibrary(\"svars\")\nVAR        &lt;- vars::VAR(DATA[,c(1,2,3)],p =2,type = \"const\")\nVAR$varresult$c$coefficients\n\n       c.l1        y.l1        x.l1        c.l2        y.l2        x.l2 \n 1.12127681  0.15372782  0.29159136 -0.11201301 -0.01109658  0.18036079 \n      const \n-9.91395632 \n\nVAR$varresult$y$coefficients\n\n       c.l1        y.l1        x.l1        c.l2        y.l2        x.l2 \n-0.25412909  0.57678412  0.39960337  0.27004423 -0.15357170 -0.02784201 \n      const \n-5.84527946 \n\nVAR$varresult$x$coefficients\n\n       c.l1        y.l1        x.l1        c.l2        y.l2        x.l2 \n 0.18016081 -0.13225215  0.28849915 -0.26998876 -0.03531496  0.45762387 \n      const \n 6.70493277 \n\nSIGMA&lt;-summary(VAR)\nSIGMA$covres\n\n          c         y         x\nc 1.2422579  2.067672 0.1369263\ny 2.0676722 13.450295 0.5679060\nx 0.1369263  0.567906 1.6557099\n\n\nHabiendo estimado el VAR a continuación encontramos las restricciones de corto o contemporáneas y largo plazo:\n\nBQMODEL&lt;- BQ(VAR)\nsummary(BQMODEL)\n\n\nSVAR Estimation Results:\n======================== \n\nCall:\nBQ(x = VAR)\n\nType: Blanchard-Quah \nSample size: 25 \nLog Likelihood: -144.025 \n\nEstimated contemporaneous impact matrix:\n        c      y       x\nc 0.45904 0.3686 -0.9464\ny 0.08455 3.5899 -0.7455\nx 1.15782 0.2366  0.5091\n\nEstimated identified long run impact matrix:\n        c      y     x\nc 16.7627  0.000 0.000\ny -0.1924  4.788 0.000\nx -1.2435 -2.228 2.005\n\nCovariance matrix of reduced form residuals (*100):\n       c       y      x\nc 124.23  206.77  13.69\ny 206.77 1345.03  56.79\nx  13.69   56.79 165.57\n\n\nEn seguida, calculamos la función impulso respuesta para cada variable, teniendo en cuenta que el PIB y la proporción de activos del sistema bancario invertidos en títulos y valores del gobierno no sufren en el largo plazo ningún efecto de los tres shocks estructurales.\n\nFIR_BQ &lt;- irf(BQMODEL,n.ahead = 32, impulse = c( \"c\", \"y\", \"x\"), boot =FALSE)\ntecno  &lt;- cbind(cumsum(FIR_BQ$irf$c[, 1]), FIR_BQ$irf$c[, 2],  FIR_BQ$irf$c[, 3])\nRESULTADO1&lt;-as.data.frame(tecno)\nPERIODO&lt;-seq(1,33,1)\nRESULTADO1 &lt;-cbind(RESULTADO1,PERIODO)\nCODE&lt;-rep(\"Tecnológico\",33)\nRESULTADO1 &lt;-cbind(RESULTADO1,CODE)\n######################################\ndemanda &lt;- cbind(FIR_BQ$irf$y[, 1], FIR_BQ$irf$y[, 2],  FIR_BQ$irf$y[, 3])\nRESULTADO2&lt;-as.data.frame(demanda)\nRESULTADO2 &lt;-cbind(RESULTADO2,PERIODO)\nCODE&lt;-rep(\"Demanda\",33)\nRESULTADO2 &lt;-cbind(RESULTADO2,CODE)\n######################################\nfiscal &lt;- cbind(-1*FIR_BQ$irf$x[, 1], -1*FIR_BQ$irf$x[, 2], -1*FIR_BQ$irf$x[, 3])\nRESULTADO3 &lt;-as.data.frame(fiscal)\nRESULTADO3 &lt;-cbind(RESULTADO3,PERIODO)\nCODE&lt;-rep(\"Fiscal\",33)\nRESULTADO3&lt;-cbind(RESULTADO3,CODE)\nRESULTADO &lt;-rbind(RESULTADO1,RESULTADO2,RESULTADO3)\nBASE_LONG &lt;- gather(RESULTADO, key=\"measure\", value=\"value\",c(\"V1\", \"V2\", \"V3\"))\nBASE_LONG$measure &lt;- factor(BASE_LONG$measure,levels = ,c(\"V1\", \"V2\", \"V3\"))\nBASE_LONG$CODE &lt;- factor(BASE_LONG$CODE,levels = c(\"Tecnológico\", \"Demanda\", \"Fiscal\"))\n\nvariable_names &lt;- list(\n  \"Tecnológico\" = \"Shock tecnológicos\", \n  \"Demanda\" = \"Shock de demanda\",\n  \"Fiscal\" = \"Shock fiscal\"\n)\n\nvariable_labeller2 &lt;- function(variable,value){\n  if (variable=='CODE') {\n    return(variable_names[value])\n  } else {\n    return(region_names)\n  }\n}\npaleta&lt;-c(\"blue\",\"red\", \"burlywood\")\nZ&lt;-ggplot(BASE_LONG, aes(x=PERIODO, y=value, group = measure,\n                         colour=measure))+\n  facet_wrap(.~CODE, scales=\"free\", labeller= variable_labeller2)\nZ&lt;-Z+labs(y=\"Respuesta (%)\",\n          x=\"Períodos (trimestres)\", title = \"Guatemala: funciones impulso respuestas\",\n          caption = \"Elaboración propia con base en: https://www.secmca.org/wp-content/uploads/2023/03/REPORTE_INDICADO\nRES_BANCARIOS_MARZO_2023.xlsx\")+\n  geom_hline(yintercept=0, linetype=\"dashed\",\n             color = \"black\", size=1)+\n  geom_line(size=1.5)+\n  scale_color_manual(values=paleta,\n                     labels = c(\"Crédito para consumo\",\n                                \"Producto\",\n                                \"Proporción de los activos invertidos en valores públicos\"\n                                ))\nZ&lt;-Z+theme(axis.line.x = element_line(colour = \"black\", size = 0.5),\n           axis.line.y.left  = element_line(colour = \"black\", size = 0.5),\n           axis.line.y.right = element_blank(),\n           axis.text.x  = element_text( color = \"black\", size = 14),\n           axis.text.y  = element_text( color = \"black\", size = 14),\n           axis.title.x = element_text( color = \"black\", size = 15),\n           axis.title.y = element_text( color = \"black\", size = 15),\n           panel.grid.minor = element_blank(),\n           panel.grid.major.y = element_blank(),\n           panel.grid.major.x = element_blank(),\n           panel.border = element_blank(),\n           panel.background = element_blank(),\n           legend.key=element_rect(fill = \"white\", colour = \"white\",\n                                   color = \"white\", inherit.blank = FALSE),\n           legend.title = element_blank(),\n           legend.text  = element_text(size=18),\n           legend.position=\"bottom\",\n           legend.spacing.x = unit(0.10, 'cm'),\n           legend.margin=margin(),\n           legend.background = element_rect(fill = \"white\", colour = \"transparent\",\n                                            color = \"white\", inherit.blank = FALSE),\n           strip.text.x = element_text(\n             size = 20, color = \"black\", face = \"bold.italic\"\n           )\n)+guides(color = guide_legend(nrow = 1))+\n  scale_x_continuous(breaks=seq(0,32,4))\nZ\n\n\n\n\nInplicaciones\n\n#Descomposición de la varianza HISTÓRICA\n##FUNCIONES\nVARhd &lt;- function(Estimation){\n  ## make X and Y\n  nlag    &lt;- Estimation$p   # number of lags\n  DATA    &lt;- Estimation$y   # data\n  QQ      &lt;- VARmakexy(DATA,nlag,1)\n  #invA   &lt;- t(chol(as.matrix(summary(Estimation)$covres)))# inverse of the A matrix\n  invA    &lt;- BQMODEL$LRIM\n  #invA   &lt;- bqfactor\n  Fcomp   &lt;- companionmatrix(Estimation)                   # Companion matrix\n  #det    &lt;- c_case                                       # constant and/or trends\n  F1      &lt;- t(QQ$Ft)                                     # make comparable to notes\n  eps     &lt;- ginv(invA) %*% t(residuals(Estimation))\n  # structural errors\n  nvar    &lt;- Estimation$K                                 # number of endogenous variables\n  nvarXeq &lt;- nvar * nlag                                  # number of lagged endogenous per equation\n  nvar_ex &lt;- 0                                                # number of exogenous (excluding constant and trend)\n  Y       &lt;- QQ$Y                                             # left-hand side\n  #X     &lt;- QQ$X[,(1+det):(nvarXeq+det)]                    # right-hand side (no exogenous)\n  nobs    &lt;- nrow(Y)                                          # number of observations\n  ## Compute historical decompositions\n  # Contribution of each shock\n  invA_big    &lt;- matrix(0,nvarXeq,nvar)\n  invA_big[1:nvar,] &lt;- invA\n  Icomp       &lt;- cbind(diag(nvar), matrix(0,nvar,(nlag-1)*nvar))\n  HDshock_big &lt;- array(0, dim=c(nlag*nvar,nobs+1,nvar))\n  HDshock     &lt;- array(0, dim=c(nvar,(nobs+1),nvar))\n\n  for (j in 1:nvar){  # for each variable\n    eps_big &lt;- matrix(0,nvar,(nobs+1)) # matrix of shocks conformable with companion\n    eps_big[j,2:ncol(eps_big)] &lt;- eps[j,]\n    for (i in 2:(nobs+1)){\n      HDshock_big[,i,j] &lt;- invA_big %*% eps_big[,i] + Fcomp %*% HDshock_big[,(i-1),j]\n      HDshock[,i,j] &lt;-  Icomp %*% HDshock_big[,i,j]\n    }\n  }\n\n  HD.shock &lt;- array(0, dim=c((nobs+nlag),nvar,nvar))   # [nobs x shock x var]\n\n  for (i in 1:nvar){\n    for (j in 1:nvar){\n      HD.shock[,j,i] &lt;- c(rep(NA,nlag), HDshock[i,(2:dim(HDshock)[2]),j])\n    }\n  }\n\n  return(HD.shock)\n\n}\n##########\nVARmakexy &lt;- function(DATA,lags,c_case){\n  nobs &lt;- nrow(DATA)\n  #Y matrix\n  Y &lt;- DATA[(lags+1):nrow(DATA),]\n  Y &lt;- DATA[-c(1:lags),]\n  #X-matrix\n  if (c_case==0){\n    X &lt;- NA\n    for (jj in 0:(lags-1)){\n      X &lt;- rbind(DATA[(jj+1):(nobs-lags+jj),])\n    }\n  } else if(c_case==1){ #constant\n    X &lt;- NA\n    for (jj in 0:(lags-1)){\n      X &lt;- rbind(DATA[(jj+1):(nobs-lags+jj),])\n    }\n    X &lt;- cbind(matrix(1,(nobs-lags),1), X)\n  } else if(c_case==2){ # time trend and constant\n    X &lt;- NA\n    for (jj in 0:(lags-1)){\n      X &lt;- rbind(DATA[(jj+1):(nobs-lags+jj),])\n    }\n    trend &lt;- c(1:nrow(X))\n    X &lt;-cbind(matrix(1,(nobs-lags),1), t(trend))\n  }\n  A &lt;- (t(X) %*% as.matrix(X))\n  B &lt;- (as.matrix(t(X)) %*% as.matrix(Y))\n\n  Ft &lt;- ginv(A) %*% B\n  retu &lt;- list(X=X,Y=Y, Ft=Ft)\n  return(retu)\n}\n\ncompanionmatrix &lt;- function (x)\n{\n  if (!(class(x) == \"varest\")) {\n    stop(\"\\nPlease provide an object of class 'varest', generated by 'VAR()'.\\n\")\n  }\n  K &lt;- x$K\n  p &lt;- x$p\n  A &lt;- unlist(Acoef(x))\n  companion &lt;- matrix(0, nrow = K * p, ncol = K * p)\n  companion[1:K, 1:(K * p)] &lt;- A\n  if (p &gt; 1) {\n    j &lt;- 0\n    for (i in (K + 1):(K * p)) {\n      j &lt;- j + 1\n      companion[i, j] &lt;- 1\n    }\n  }\n  return(companion)\n}\n\n\nSERIE &lt;-fitted(VAR)\nBQh&lt;-VARhd(VAR)\ndates1&lt;- seq(as.Date(\"2016-03-01\"), length=length(SERIE[,1])+2,by=\"quarters\")\nBQc_T&lt;-BQh[,1,1] #SHOCK TECNOLÓGICO SOBRE c\nBQc_T&lt;-xts(BQc_T, order.by=dates1)\nBQc_D&lt;-BQh[,1,2] #SHOCK DEMANDA SOBRE c\nBQc_D&lt;-xts(BQc_D, order.by=dates1)\nBQc_F&lt;-BQh[,1,3] #SHOCK DEMANDA2 SOBRE c\nBQc_F&lt;-xts(BQc_F, order.by=dates1)"
  },
  {
    "objectID": "posts/post-with-code/index.html#blanchard-quah-ortogonalización-restricciones-sobre-c1",
    "href": "posts/post-with-code/index.html#blanchard-quah-ortogonalización-restricciones-sobre-c1",
    "title": "MODELOS SEMI ESTRUCTURALES PARA EL CRÉDITO AL CONSUMO",
    "section": "",
    "text": "Al observar la evolución del crédito hacia consumo provisto por el sistema bancario guatemalteco y disponible en @SECMCADATOS, se observa una series con una tendendencia estocástica.\n\nlibrary(\"zoo\")\nlibrary(\"xts\")\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(kableExtra)\nlibrary(xtable)\nlibrary(tidyr)\nlibrary(quantmod)\nlibrary(RColorBrewer)\nlibrary(gridExtra)\n#CARGAMOS DATOS MENSUALES\nDATA_MES&lt;-as.xts(read.zoo(\"GT_MES.csv\", index.column = 1,\n          sep = \";\", header=TRUE, format = \"%Y-%m-%d\"))\nCREDITO&lt;-DATA_MES$CRED\nCREDITO&lt;-data.frame(date=index(CREDITO), coredata(CREDITO))\nCREDITO&lt;-filter(CREDITO, date &gt;= \"2008-01-01\")\ncolnames(CREDITO)&lt;-c(\"date\",\"CREDITO\")\nCREDITO&lt;-mutate(CREDITO, CONSUMO=log(CREDITO))\nG&lt;-ggplot(CREDITO, aes(x=date, y=CONSUMO))\nG&lt;-G+labs(y=\"Logaritmo\",\n          x=\"Fecha\", title = \"Guatemala: evolución del crédito al consumo\",\n          caption = \"https://www.secmca.org/wp-content/uploads/2023/03/REPORTE_INDICADO\nRES_BANCARIOS_MARZO_2023.xlsx\")+\n  geom_line(size=1.5)\nG\n\n\n\n\nEl proceso de generación de la serie del crédito al consumo puede explicarse a través de la identificación de diferentes innovaciones. Una de ellas, las llamaré tecnológicas (en general uso ese término para referir los factores que pueden producir una mayor inclusión financiera independientemente si es producto de políticas o nuevas tecnologías), la segunda las de denanda y la tercera de absorción fiscal.\nPara este ejercicio de identificación sigo la metodología propuesta por @BLANCHARD88 y estimo la forma reducida de un Vector Autorregresivo integrado por la tasa de crecimiento de la cartera de consumo nominal (\\(\\Delta c_{t}\\)), la tasa de crecimiento del PIB (\\(\\Delta y_{t}\\)) y el porcentaje de los activos de los sistemas bancarios en títulos y valores públicos (\\(\\Delta y_{t}\\)). La representación de este VAR como un proceso de media móviles está dado por:\n\\[\\begin{equation}\nX_{t}=\\left( \\begin{array}{c}\n\\Delta c_{t} \\\\\n\\Delta y_{t} \\\\\n\\Delta x_{t}\n\\end{array}\n\\right)=A(L)e_{t}\n\\label{e1}\n\\end{equation}\\]\nConsidero \\(A(0)=I\\) y \\(\\Sigma_e=E(e e^{\\tau})\\) como la matriz de varianza y covarianza de la forma reducida del VAR mostrado en \\(\\ref{e1}\\). Y supongo, primero que el crédito hacia consumo, la actividad económica y la exposición del sistema bancario hacia valores del gobierno son producidos a través de tres procesos estructurales independientes con shocks de varianza unitaria. Y segundo, que uno de esos procesos, el de las innovaciones tecnológicas, es el responsable de la tendencia estocástica observada en el crédito para consumo. Con base en lo anterior defino un VAR estructural cuya representación como un proceso de medias móviles es el siguiente:\n\\[\\begin{equation}\nX_{t}=C(L)\\epsilon_{t}=\\left( \\begin{array}{ccc}\nC_{1,1}(L) & C_{1,2}(L) & C_{1,3}(L)\\\\\nC_{2,1}(L) & C_{2,2}(L) & C_{2,3}(L)\\\\\nC_{3,1}(L) & C_{3,2}(L) & C_{3,3}(L)\n\\end{array}\n\\right)\\epsilon_{t}\n\\label{e2}\n\\end{equation}\\]\nSiendo \\(\\Sigma_{\\epsilon}=E(\\epsilon \\epsilon^{\\tau})=I\\) la matriz de varianza y covarianza de los shocks estructurales, los cuales son independientes y con varianza unitaria, y \\(C_{1,2}(1)=C_{1,3}(1)=0\\), indicando que el shock de demanda y fiscal sobre las variables tasa de crecimiento del PIB y porcentaje de activos invertidos en valores soberanos, en su orden, no tienen efectos de largo plazo en el crédito nominal para consumo.\nEl proceso y resultado de la estimación es el siguiente:\n\nCRED       &lt;-DATA_MES$CRED\nFISCAL     &lt;-DATA_MES$PUB\nCRED       &lt;-CRED[\"2008-01-01/2022-09-01\"]\nep1        &lt;-endpoints(CRED , on = \"quarters\")\nCRED       &lt;-period.apply(CRED  , INDEX = ep1, FUN = sum)\nDCRED      &lt;-diff(100*log(CRED ), lag=4)\nFISCAL     &lt;-FISCAL[\"2008-01-01/2022-09-01\"]\nep2        &lt;-endpoints(FISCAL , on = \"quarters\")\nTASA       &lt;-period.apply(FISCAL, INDEX = ep2, FUN = max)\nDATA_TRIM   &lt;-as.xts(read.zoo(\"TRIM_GT.csv\", index.column = 1,\n                      sep = \";\", header=TRUE, format = \"%Y-%m-%d\"))\nPIB         &lt;-DATA_TRIM$PIB\nPIB         &lt;-PIB[\"2001-03-01/2022-09-01\"]\nDPIB        &lt;-diff(100*log(PIB), lag=4)\n#COMBINAR\nBASE       &lt;-merge(DCRED, DPIB,join=\"left\")\nBASE       &lt;-merge(BASE,  FISCAL,join=\"left\")\nBASE       &lt;-data.frame(date=index(BASE), coredata(BASE))\ncolnames(BASE)&lt;-c(\"date\",\"c\", \"y\", 'x')\nDATA       &lt;-dplyr::select(BASE, date, c,y,x)\ncolnames(DATA)&lt;-c(\"date\", \"c\", \"y\", 'x')\nDATA       &lt;-filter(DATA, date &gt;= \"2016-03-01\")\nDATA       &lt;-xts(DATA[,-1], order.by=as.Date(DATA[,1], \"%Y/%m/%d\"))\nlibrary(\"svars\")\nVAR        &lt;- vars::VAR(DATA[,c(1,2,3)],p =2,type = \"const\")\nVAR$varresult$c$coefficients\n\n       c.l1        y.l1        x.l1        c.l2        y.l2        x.l2 \n 1.12127681  0.15372782  0.29159136 -0.11201301 -0.01109658  0.18036079 \n      const \n-9.91395632 \n\nVAR$varresult$y$coefficients\n\n       c.l1        y.l1        x.l1        c.l2        y.l2        x.l2 \n-0.25412909  0.57678412  0.39960337  0.27004423 -0.15357170 -0.02784201 \n      const \n-5.84527946 \n\nVAR$varresult$x$coefficients\n\n       c.l1        y.l1        x.l1        c.l2        y.l2        x.l2 \n 0.18016081 -0.13225215  0.28849915 -0.26998876 -0.03531496  0.45762387 \n      const \n 6.70493277 \n\nSIGMA&lt;-summary(VAR)\nSIGMA$covres\n\n          c         y         x\nc 1.2422579  2.067672 0.1369263\ny 2.0676722 13.450295 0.5679060\nx 0.1369263  0.567906 1.6557099\n\n\nHabiendo estimado el VAR a continuación encontramos las restricciones de corto o contemporáneas y largo plazo:\n\nBQMODEL&lt;- BQ(VAR)\nsummary(BQMODEL)\n\n\nSVAR Estimation Results:\n======================== \n\nCall:\nBQ(x = VAR)\n\nType: Blanchard-Quah \nSample size: 25 \nLog Likelihood: -144.025 \n\nEstimated contemporaneous impact matrix:\n        c      y       x\nc 0.45904 0.3686 -0.9464\ny 0.08455 3.5899 -0.7455\nx 1.15782 0.2366  0.5091\n\nEstimated identified long run impact matrix:\n        c      y     x\nc 16.7627  0.000 0.000\ny -0.1924  4.788 0.000\nx -1.2435 -2.228 2.005\n\nCovariance matrix of reduced form residuals (*100):\n       c       y      x\nc 124.23  206.77  13.69\ny 206.77 1345.03  56.79\nx  13.69   56.79 165.57\n\n\nEn seguida, calculamos la función impulso respuesta para cada variable, teniendo en cuenta que el PIB y la proporción de activos del sistema bancario invertidos en títulos y valores del gobierno no sufren en el largo plazo ningún efecto de los tres shocks estructurales.\n\nFIR_BQ &lt;- irf(BQMODEL,n.ahead = 32, impulse = c( \"c\", \"y\", \"x\"), boot =FALSE)\ntecno  &lt;- cbind(cumsum(FIR_BQ$irf$c[, 1]), FIR_BQ$irf$c[, 2],  FIR_BQ$irf$c[, 3])\nRESULTADO1&lt;-as.data.frame(tecno)\nPERIODO&lt;-seq(1,33,1)\nRESULTADO1 &lt;-cbind(RESULTADO1,PERIODO)\nCODE&lt;-rep(\"Tecnológico\",33)\nRESULTADO1 &lt;-cbind(RESULTADO1,CODE)\n######################################\ndemanda &lt;- cbind(FIR_BQ$irf$y[, 1], FIR_BQ$irf$y[, 2],  FIR_BQ$irf$y[, 3])\nRESULTADO2&lt;-as.data.frame(demanda)\nRESULTADO2 &lt;-cbind(RESULTADO2,PERIODO)\nCODE&lt;-rep(\"Demanda\",33)\nRESULTADO2 &lt;-cbind(RESULTADO2,CODE)\n######################################\nfiscal &lt;- cbind(-1*FIR_BQ$irf$x[, 1], -1*FIR_BQ$irf$x[, 2], -1*FIR_BQ$irf$x[, 3])\nRESULTADO3 &lt;-as.data.frame(fiscal)\nRESULTADO3 &lt;-cbind(RESULTADO3,PERIODO)\nCODE&lt;-rep(\"Fiscal\",33)\nRESULTADO3&lt;-cbind(RESULTADO3,CODE)\nRESULTADO &lt;-rbind(RESULTADO1,RESULTADO2,RESULTADO3)\nBASE_LONG &lt;- gather(RESULTADO, key=\"measure\", value=\"value\",c(\"V1\", \"V2\", \"V3\"))\nBASE_LONG$measure &lt;- factor(BASE_LONG$measure,levels = ,c(\"V1\", \"V2\", \"V3\"))\nBASE_LONG$CODE &lt;- factor(BASE_LONG$CODE,levels = c(\"Tecnológico\", \"Demanda\", \"Fiscal\"))\n\nvariable_names &lt;- list(\n  \"Tecnológico\" = \"Shock tecnológicos\", \n  \"Demanda\" = \"Shock de demanda\",\n  \"Fiscal\" = \"Shock fiscal\"\n)\n\nvariable_labeller2 &lt;- function(variable,value){\n  if (variable=='CODE') {\n    return(variable_names[value])\n  } else {\n    return(region_names)\n  }\n}\npaleta&lt;-c(\"blue\",\"red\", \"burlywood\")\nZ&lt;-ggplot(BASE_LONG, aes(x=PERIODO, y=value, group = measure,\n                         colour=measure))+\n  facet_wrap(.~CODE, scales=\"free\", labeller= variable_labeller2)\nZ&lt;-Z+labs(y=\"Respuesta (%)\",\n          x=\"Períodos (trimestres)\", title = \"Guatemala: funciones impulso respuestas\",\n          caption = \"Elaboración propia con base en: https://www.secmca.org/wp-content/uploads/2023/03/REPORTE_INDICADO\nRES_BANCARIOS_MARZO_2023.xlsx\")+\n  geom_hline(yintercept=0, linetype=\"dashed\",\n             color = \"black\", size=1)+\n  geom_line(size=1.5)+\n  scale_color_manual(values=paleta,\n                     labels = c(\"Crédito para consumo\",\n                                \"Producto\",\n                                \"Proporción de los activos invertidos en valores públicos\"\n                                ))\nZ&lt;-Z+theme(axis.line.x = element_line(colour = \"black\", size = 0.5),\n           axis.line.y.left  = element_line(colour = \"black\", size = 0.5),\n           axis.line.y.right = element_blank(),\n           axis.text.x  = element_text( color = \"black\", size = 14),\n           axis.text.y  = element_text( color = \"black\", size = 14),\n           axis.title.x = element_text( color = \"black\", size = 15),\n           axis.title.y = element_text( color = \"black\", size = 15),\n           panel.grid.minor = element_blank(),\n           panel.grid.major.y = element_blank(),\n           panel.grid.major.x = element_blank(),\n           panel.border = element_blank(),\n           panel.background = element_blank(),\n           legend.key=element_rect(fill = \"white\", colour = \"white\",\n                                   color = \"white\", inherit.blank = FALSE),\n           legend.title = element_blank(),\n           legend.text  = element_text(size=18),\n           legend.position=\"bottom\",\n           legend.spacing.x = unit(0.10, 'cm'),\n           legend.margin=margin(),\n           legend.background = element_rect(fill = \"white\", colour = \"transparent\",\n                                            color = \"white\", inherit.blank = FALSE),\n           strip.text.x = element_text(\n             size = 20, color = \"black\", face = \"bold.italic\"\n           )\n)+guides(color = guide_legend(nrow = 1))+\n  scale_x_continuous(breaks=seq(0,32,4))\nZ\n\n\n\n\nInplicaciones\n\n#Descomposición de la varianza HISTÓRICA\n##FUNCIONES\nVARhd &lt;- function(Estimation){\n  ## make X and Y\n  nlag    &lt;- Estimation$p   # number of lags\n  DATA    &lt;- Estimation$y   # data\n  QQ      &lt;- VARmakexy(DATA,nlag,1)\n  #invA   &lt;- t(chol(as.matrix(summary(Estimation)$covres)))# inverse of the A matrix\n  invA    &lt;- BQMODEL$LRIM\n  #invA   &lt;- bqfactor\n  Fcomp   &lt;- companionmatrix(Estimation)                   # Companion matrix\n  #det    &lt;- c_case                                       # constant and/or trends\n  F1      &lt;- t(QQ$Ft)                                     # make comparable to notes\n  eps     &lt;- ginv(invA) %*% t(residuals(Estimation))\n  # structural errors\n  nvar    &lt;- Estimation$K                                 # number of endogenous variables\n  nvarXeq &lt;- nvar * nlag                                  # number of lagged endogenous per equation\n  nvar_ex &lt;- 0                                                # number of exogenous (excluding constant and trend)\n  Y       &lt;- QQ$Y                                             # left-hand side\n  #X     &lt;- QQ$X[,(1+det):(nvarXeq+det)]                    # right-hand side (no exogenous)\n  nobs    &lt;- nrow(Y)                                          # number of observations\n  ## Compute historical decompositions\n  # Contribution of each shock\n  invA_big    &lt;- matrix(0,nvarXeq,nvar)\n  invA_big[1:nvar,] &lt;- invA\n  Icomp       &lt;- cbind(diag(nvar), matrix(0,nvar,(nlag-1)*nvar))\n  HDshock_big &lt;- array(0, dim=c(nlag*nvar,nobs+1,nvar))\n  HDshock     &lt;- array(0, dim=c(nvar,(nobs+1),nvar))\n\n  for (j in 1:nvar){  # for each variable\n    eps_big &lt;- matrix(0,nvar,(nobs+1)) # matrix of shocks conformable with companion\n    eps_big[j,2:ncol(eps_big)] &lt;- eps[j,]\n    for (i in 2:(nobs+1)){\n      HDshock_big[,i,j] &lt;- invA_big %*% eps_big[,i] + Fcomp %*% HDshock_big[,(i-1),j]\n      HDshock[,i,j] &lt;-  Icomp %*% HDshock_big[,i,j]\n    }\n  }\n\n  HD.shock &lt;- array(0, dim=c((nobs+nlag),nvar,nvar))   # [nobs x shock x var]\n\n  for (i in 1:nvar){\n    for (j in 1:nvar){\n      HD.shock[,j,i] &lt;- c(rep(NA,nlag), HDshock[i,(2:dim(HDshock)[2]),j])\n    }\n  }\n\n  return(HD.shock)\n\n}\n##########\nVARmakexy &lt;- function(DATA,lags,c_case){\n  nobs &lt;- nrow(DATA)\n  #Y matrix\n  Y &lt;- DATA[(lags+1):nrow(DATA),]\n  Y &lt;- DATA[-c(1:lags),]\n  #X-matrix\n  if (c_case==0){\n    X &lt;- NA\n    for (jj in 0:(lags-1)){\n      X &lt;- rbind(DATA[(jj+1):(nobs-lags+jj),])\n    }\n  } else if(c_case==1){ #constant\n    X &lt;- NA\n    for (jj in 0:(lags-1)){\n      X &lt;- rbind(DATA[(jj+1):(nobs-lags+jj),])\n    }\n    X &lt;- cbind(matrix(1,(nobs-lags),1), X)\n  } else if(c_case==2){ # time trend and constant\n    X &lt;- NA\n    for (jj in 0:(lags-1)){\n      X &lt;- rbind(DATA[(jj+1):(nobs-lags+jj),])\n    }\n    trend &lt;- c(1:nrow(X))\n    X &lt;-cbind(matrix(1,(nobs-lags),1), t(trend))\n  }\n  A &lt;- (t(X) %*% as.matrix(X))\n  B &lt;- (as.matrix(t(X)) %*% as.matrix(Y))\n\n  Ft &lt;- ginv(A) %*% B\n  retu &lt;- list(X=X,Y=Y, Ft=Ft)\n  return(retu)\n}\n\ncompanionmatrix &lt;- function (x)\n{\n  if (!(class(x) == \"varest\")) {\n    stop(\"\\nPlease provide an object of class 'varest', generated by 'VAR()'.\\n\")\n  }\n  K &lt;- x$K\n  p &lt;- x$p\n  A &lt;- unlist(Acoef(x))\n  companion &lt;- matrix(0, nrow = K * p, ncol = K * p)\n  companion[1:K, 1:(K * p)] &lt;- A\n  if (p &gt; 1) {\n    j &lt;- 0\n    for (i in (K + 1):(K * p)) {\n      j &lt;- j + 1\n      companion[i, j] &lt;- 1\n    }\n  }\n  return(companion)\n}\n\n\nSERIE &lt;-fitted(VAR)\nBQh&lt;-VARhd(VAR)\ndates1&lt;- seq(as.Date(\"2016-03-01\"), length=length(SERIE[,1])+2,by=\"quarters\")\nBQc_T&lt;-BQh[,1,1] #SHOCK TECNOLÓGICO SOBRE c\nBQc_T&lt;-xts(BQc_T, order.by=dates1)\nBQc_D&lt;-BQh[,1,2] #SHOCK DEMANDA SOBRE c\nBQc_D&lt;-xts(BQc_D, order.by=dates1)\nBQc_F&lt;-BQh[,1,3] #SHOCK DEMANDA2 SOBRE c\nBQc_F&lt;-xts(BQc_F, order.by=dates1)"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]